{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epFeagZZCOBK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load and preprocess the text\n",
        "with open('/content/Semed_Vurgun_seirleri.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read().lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "53RKXgGA6Akg",
        "outputId": "25aea3a1-3db3-403e-e74a-86e3be183f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncavanlara xi̇tab\\nmənim düşkün könlüm sizdən eləyir\\nbu fərz*\\n olan təmənnanı, cavanlar.\\nunutmayın bə'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(sorted(set(text.lower())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4nFRz-cJQzn4",
        "outputId": "6beb6bab-e7b1-41ee-f1a5-312963c00d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\x01\\n !\"\\'()*,-./0123456789:;<>?[\\\\]^abcdefghijklmnopqrstuvwxyz§°»äçöüğışə̇–—‘’“”†‡…★'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = re.sub(r'[^a-zA-Zəğıöçşüı\\s\\n]', '', text)"
      ],
      "metadata": {
        "id": "lzSOVxtaQ5Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(sorted(set(text.lower())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bOM0E3SHRgtL",
        "outputId": "9598fb44-8f8d-4f4f-a15f-29137d461650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n abcdefghijklmnopqrstuvwxyzçöüğışə'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FUKSRGxJ5n2A",
        "outputId": "0dbf2aba-b95c-4f55-d317-2a63185ef700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncavanlara xitab\\nmənim düşkün könlüm sizdən eləyir\\nbu fərz\\n olan təmənnanı cavanlar\\nunutmayın bəşər '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split = \"character\",\n",
        "                                                   standardize = 'lower')\n",
        "\n",
        "text_vec_layer.adapt(text)\n",
        "encoded = text_vec_layer([text][0])"
      ],
      "metadata": {
        "id": "PIDZlzcJR4aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded -= 2\n",
        "vocab_size = text_vec_layer.vocabulary_size() -2\n",
        "dataset_size = len(encoded)"
      ],
      "metadata": {
        "id": "FeKLXKz3Sz5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM0cIqk2S1MY",
        "outputId": "200262a8-7c29-45bf-cfa7-71e92a1acf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsgUQvk_S2aq",
        "outputId": "b1a80c90-6cbf-42c9-f314-3be70ffce6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "794641"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, seed =None, shuffle = False, batch_size = 32):\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift = 1, drop_remainder = True)\n",
        "    ds = ds.flat_map(lambda window: window.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(10000)\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).repeat().prefetch(1)"
      ],
      "metadata": {
        "id": "YcmYZjv5TPYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length  =100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:600_000], length = length, shuffle = True,\n",
        "                       seed = 42)\n",
        "valid_set = to_dataset(encoded[600_000:675_000], length = length)\n",
        "test_set = to_dataset(encoded[675_000:], length = length)"
      ],
      "metadata": {
        "id": "P75dIdxJVSzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = 16),\n",
        "    tf.keras.layers.LSTM(128, return_sequences = True),\n",
        "    tf.keras.layers.Dense(vocab_size, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Nadam(learning_rate = 1e-3),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint('Semed_Vurgun.keras',\n",
        "                                                monitor = \"val_accuracy\",\n",
        "                                                save_best_only = True)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\",\n",
        "                                              patience = 3,\n",
        "                                              restore_best_weights = True)\n",
        "num_windows = 600_000 - length\n",
        "steps_per_epoch = num_windows // 32\n",
        "\n",
        "val_windows = 75_000 - length\n",
        "validation_steps = val_windows // 32\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data = valid_set,\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    validation_steps = validation_steps,\n",
        "    epochs = 10,\n",
        "    callbacks = [model_ckpt, early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vy14MxrVlfa",
        "outputId": "f9819936-7e99-449e-f685-c0d80070db49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 8ms/step - accuracy: 0.4768 - loss: 1.7340 - val_accuracy: 0.4199 - val_loss: 2.0565\n",
            "Epoch 2/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 8ms/step - accuracy: 0.5749 - loss: 1.4139 - val_accuracy: 0.4356 - val_loss: 1.9843\n",
            "Epoch 3/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 8ms/step - accuracy: 0.5773 - loss: 1.3950 - val_accuracy: 0.4453 - val_loss: 1.9340\n",
            "Epoch 4/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 8ms/step - accuracy: 0.5758 - loss: 1.3887 - val_accuracy: 0.4486 - val_loss: 1.9221\n",
            "Epoch 5/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5774 - loss: 1.3819 - val_accuracy: 0.4512 - val_loss: 1.8995\n",
            "Epoch 6/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5765 - loss: 1.3807 - val_accuracy: 0.4560 - val_loss: 1.8821\n",
            "Epoch 7/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5764 - loss: 1.3782 - val_accuracy: 0.4564 - val_loss: 1.8726\n",
            "Epoch 8/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5759 - loss: 1.3767 - val_accuracy: 0.4582 - val_loss: 1.8678\n",
            "Epoch 9/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5757 - loss: 1.3756 - val_accuracy: 0.4623 - val_loss: 1.8534\n",
            "Epoch 10/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 8ms/step - accuracy: 0.5756 - loss: 1.3757 - val_accuracy: 0.4611 - val_loss: 1.8499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eea108e28d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda x: x-2), #No <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "ASjk2uIPV2M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = model.predict(tf.constant([\"Sala\"]))[0,-1]\n",
        "y_pred = tf.argmax(y_proba)\n",
        "text_vec_layer.get_vocabulary()[y_pred+2]"
      ],
      "metadata": {
        "id": "xYPcqHJHcJHg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0559856e-1e83-4eb9-c66d-cf2979f1e600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.str_('r')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temprature):\n",
        "    text = tf.constant([text])\n",
        "    y_proba = model.predict(text)[0,-1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temprature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples = 1)[0,0].numpy()\n",
        "    return text_vec_layer.get_vocabulary()[char_id+2 ]"
      ],
      "metadata": {
        "id": "dOT6Ac-gccIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_text(text, chars = 20, temprature = 1):\n",
        "    for _ in range(chars):\n",
        "        text += next_char(text, temprature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "QdL8solAcxk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extend_text('Azərbaycan', chars = 30, temprature = 0.2)"
      ],
      "metadata": {
        "id": "Ybw6SAoHczVU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "a744e3b8-0985-40e6-919d-f739285fb1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Azərbaycan\\nbir də bu gün kimi bir haqqı '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = vocab_size\n",
        "max_length = 100\n",
        "embed_size = 16\n",
        "num_heads = 2\n",
        "ff_dim = 64\n",
        "\n",
        "inputs = tf.keras.Input(shape=(None,), dtype='int32')\n",
        "embed_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size)\n",
        "embedding = embed_layer(inputs)\n",
        "\n",
        "pos_embed_layer = tf.keras.layers.Embedding(input_dim=max_length, output_dim=embed_size)\n",
        "\n",
        "positions = tf.keras.layers.Lambda(lambda x: tf.range(start=0, limit=tf.shape(x)[1], delta=1))(inputs)\n",
        "pos_embed_dec = pos_embed_layer(positions)\n",
        "\n",
        "embed = embedding + pos_embed_dec\n",
        "\n",
        "causal_mask = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.linalg.band_part(tf.ones((tf.shape(x)[1], tf.shape(x)[1])), -1, 0)\n",
        ")(inputs)\n",
        "\n",
        "decoder_attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, \\\n",
        "                                                       key_dim=embed_size)(embed, embed, attention_mask=causal_mask)\n",
        "decoder_attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(embed + decoder_attention)\n",
        "\n",
        "decoder_ff = tf.keras.layers.Dense(ff_dim, activation='relu')(decoder_attention)\n",
        "decoder_ff = tf.keras.layers.Dense(embed_size)(decoder_ff)\n",
        "decoder_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(decoder_attention + decoder_ff)\n",
        "\n",
        "decoder_attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, \\\n",
        "                                                       key_dim=embed_size)(decoder_outputs, decoder_outputs, attention_mask=causal_mask)\n",
        "decoder_attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(decoder_outputs + decoder_attention)\n",
        "\n",
        "decoder_ff = tf.keras.layers.Dense(ff_dim, activation='relu')(decoder_attention)\n",
        "decoder_ff = tf.keras.layers.Dense(embed_size)(decoder_ff)\n",
        "decoder_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(decoder_attention + decoder_ff)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(vocab_size, activation='softmax')(decoder_outputs)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "WqroV8BfLzi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='nadam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data=valid_set,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=10,\n",
        "    callbacks=[model_ckpt, early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mttLSaK4pxrL",
        "outputId": "02f98300-2157-4095-84e8-0d0f24d663fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 5ms/step - accuracy: 0.3186 - loss: 2.2079 - val_accuracy: 0.3797 - val_loss: 2.0248\n",
            "Epoch 2/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5ms/step - accuracy: 0.3982 - loss: 1.9313 - val_accuracy: 0.3932 - val_loss: 1.9845\n",
            "Epoch 3/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4148 - loss: 1.8765 - val_accuracy: 0.3974 - val_loss: 1.9720\n",
            "Epoch 4/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4244 - loss: 1.8458 - val_accuracy: 0.4012 - val_loss: 1.9480\n",
            "Epoch 5/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5ms/step - accuracy: 0.4303 - loss: 1.8268 - val_accuracy: 0.4056 - val_loss: 1.9482\n",
            "Epoch 6/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4327 - loss: 1.8164 - val_accuracy: 0.4051 - val_loss: 1.9393\n",
            "Epoch 7/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4343 - loss: 1.8085 - val_accuracy: 0.4089 - val_loss: 1.9255\n",
            "Epoch 8/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5ms/step - accuracy: 0.4365 - loss: 1.8020 - val_accuracy: 0.4105 - val_loss: 1.9254\n",
            "Epoch 9/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4383 - loss: 1.7959 - val_accuracy: 0.4105 - val_loss: 1.9182\n",
            "Epoch 10/10\n",
            "\u001b[1m18746/18746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5ms/step - accuracy: 0.4401 - loss: 1.7903 - val_accuracy: 0.4105 - val_loss: 1.9255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ee998770490>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda x: x-2), #No <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "Bcf3a3MJqt2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = model.predict(tf.constant([\"Sala\"]))[0,-1]\n",
        "y_pred = tf.argmax(y_proba)\n",
        "text_vec_layer.get_vocabulary()[y_pred+2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "A8cjq5Le-rdy",
        "outputId": "dc87c0dd-85ff-4658-8ac8-c3b03e1e9fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.str_('r')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temprature):\n",
        "    text = tf.constant([text])\n",
        "    y_proba = model.predict(text)[0,-1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temprature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples = 1)[0,0].numpy()\n",
        "    return text_vec_layer.get_vocabulary()[char_id+2 ]"
      ],
      "metadata": {
        "id": "4yA1sxpB-x4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_text(text, chars = 20, temprature = 1):\n",
        "    for _ in range(chars):\n",
        "        text += next_char(text, temprature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "qkdYwL2l-2vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extend_text('Azərbaycan', chars = 30, temprature = 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "PwYEZZci-3OM",
        "outputId": "bad53459-26db-474e-83a6-2bb84315d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Azərbaycanın bir yeri\\ngəlir bu dalğaları'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJ_JK605-6U9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}